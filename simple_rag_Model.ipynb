{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1927c23-1f39-4f09-b200-c8765bbe9513",
   "metadata": {},
   "source": [
    "![simple_rag1](simple_rag1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87f048e3-88c6-4d57-b653-9b0f665e9de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_of_documents = [\n",
    "    \"Take a leisurely walk in the park and enjoy the fresh air.\",\n",
    "    \"Visit a local museum and discover something new.\",\n",
    "    \"Attend a live music concert and feel the rhythm.\",\n",
    "    \"Go for a hike and admire the natural scenery.\",\n",
    "    \"Have a picnic with friends and share some laughs.\",\n",
    "    \"Explore a new cuisine by dining at an ethnic restaurant.\",\n",
    "    \"Take a yoga class and stretch your body and mind.\",\n",
    "    \"Join a local sports league and enjoy some friendly competition.\",\n",
    "    \"Attend a workshop or lecture on a topic you're interested in.\",\n",
    "    \"Visit an amusement park and ride the roller coasters.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f213dd4-45fd-4ea6-8a90-7cb8a6346aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(query, document):\n",
    "    query = query.lower().split(\" \")\n",
    "    document = document.lower().split(\" \")\n",
    "    intersection = set(query).intersection(set(document))\n",
    "    union = set(query).union(set(document))\n",
    "    return len(intersection)/len(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08126873-17d2-4b05-9959-ca1c38e673f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_response(query, corpus):\n",
    "    similarities = []\n",
    "    for doc in corpus:\n",
    "        similarity = jaccard_similarity(user_input, doc)\n",
    "        similarities.append(similarity)\n",
    "    return corpus_of_documents[similarities.index(max(similarities))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a200429-9598-435e-ab1d-a5de5c48ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"What is a leisure activity that you like?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47f82b6a-c9fe-44ac-bf1f-5be01b21341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"I like to hike\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "121d1279-95b7-49ca-b8f0-08d50588c248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go for a hike and admire the natural scenery.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_response(user_input, corpus_of_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be5c274-a39f-4d5d-83ef-07951dab7fc0",
   "metadata": {},
   "source": [
    "![simple_rag2](simple_rag2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f13a5a0-6bb2-4106-8224-728f316213c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"I don't like to hike\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53bf3f20-46d1-4f7b-868e-05ccff0c3a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go for a hike and admire the natural scenery.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_response(user_input, corpus_of_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa8227c-9716-43bc-a984-60efca3bd702",
   "metadata": {},
   "source": [
    "# Adding in a LLM #\n",
    "To do this, we're going to use ollama to get up and running with an open source LLM on our local machine. We could just as easily use OpenAI's gpt-4 or Anthropic's Claude but for now, we'll start with the open source llama2 from Meta AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2e7986b-4d8f-4076-9f0f-b8b5a74966af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a50bf29c-2390-4e9c-b701-70ee40e8d33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Great! Based on your input, I recommend going for a hike in a nearby nature preserve or park. The fresh air and beautiful scenery will be sure to lift your spirits. Enjoy your hike!\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I like to hike\"\n",
    "relevant_document = return_response(user_input, corpus_of_documents)\n",
    "full_response = []\n",
    "# https://github.com/jmorganca/ollama/blob/main/docs/api.md\n",
    "prompt = \"\"\"\n",
    "You are a bot that makes recommendations for activities. You answer in very short sentences and do not include extra information.\n",
    "This is the recommended activity: {relevant_document}\n",
    "The user input is: {user_input}\n",
    "Compile a recommendation to the user based on the recommended activity and the user input.\n",
    "\"\"\"\n",
    "\n",
    "url = 'http://localhost:11434/api/generate'\n",
    "data = {\n",
    "    \"model\": \"llama2\",\n",
    "    \"prompt\": prompt.format(user_input=user_input, relevant_document=relevant_document)\n",
    "}\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "response = requests.post(url, data=json.dumps(data), headers=headers, stream=True)\n",
    "try:\n",
    "    count = 0\n",
    "    for line in response.iter_lines():\n",
    "        # filter out keep-alive new lines\n",
    "        # count += 1\n",
    "        # if count % 5== 0:\n",
    "        #     print(decoded_line['response']) # print every fifth token\n",
    "        if line:\n",
    "            decoded_line = json.loads(line.decode('utf-8'))\n",
    "            \n",
    "            full_response.append(decoded_line['response'])\n",
    "finally:\n",
    "    response.close()\n",
    "print(''.join(full_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41c1f3e-3718-4afc-8393-2dc304550901",
   "metadata": {},
   "source": [
    "![simple_rag3](simple_rag3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eefd9e12-4635-428b-9ebd-73f2d9b5f571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry to hear you don't enjoy hiking! Here's an alternative recommendation: Try visiting a local park or nature reserve for some fresh air and relaxation.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I don't like to hike\"\n",
    "relevant_document = return_response(user_input, corpus_of_documents)\n",
    "# https://github.com/jmorganca/ollama/blob/main/docs/api.md\n",
    "full_response = []\n",
    "prompt = \"\"\"\n",
    "You are a bot that makes recommendations for activities. You answer in very short sentences and do not include extra information.\n",
    "This is the recommended activity: {relevant_document}\n",
    "The user input is: {user_input}\n",
    "Compile a recommendation to the user based on the recommended activity and the user input.\n",
    "\"\"\"\n",
    "url = 'http://localhost:11434/api/generate'\n",
    "data = {\n",
    "    \"model\": \"llama2\",\n",
    "    \"prompt\": prompt.format(user_input=user_input, relevant_document=relevant_document)\n",
    "}\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "response = requests.post(url, data=json.dumps(data), headers=headers, stream=True)\n",
    "try:\n",
    "    for line in response.iter_lines():\n",
    "        # filter out keep-alive new lines\n",
    "        if line:\n",
    "            decoded_line = json.loads(line.decode('utf-8'))\n",
    "            # print(decoded_line['response'])  # uncomment to results, token by token\n",
    "            full_response.append(decoded_line['response'])\n",
    "finally:\n",
    "    response.close()\n",
    "print(''.join(full_response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
